{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19e4bbea",
      "metadata": {
        "id": "19e4bbea"
      },
      "source": [
        "# Ground2Sat reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3986cd",
      "metadata": {
        "id": "4f3986cd"
      },
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa20d4a",
      "metadata": {
        "id": "5aa20d4a"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "#\n",
        "# sys.path.append(r\"C:\\Users\\fede6\\Desktop\\AI_R\")\n",
        "# sys.path.append(r\"C:\\Users\\fede6\\Desktop\\AI_R\\Formazione\\Exercises\\CV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c43e79",
      "metadata": {
        "id": "e7c43e79"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import cv2\n",
        "import sys\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from tqdm import tqdm\n",
        "from os.path import basename\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models.swin_transformer import swin_t, Swin_T_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b01a55",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())       \n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QD0n6KPpuNOf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD0n6KPpuNOf",
        "outputId": "b6c766f9-bfd3-44c2-a057-9af4c0c37f81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive')\\n\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c8fb60",
      "metadata": {
        "id": "13c8fb60"
      },
      "source": [
        "## GLOBALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da082000",
      "metadata": {
        "id": "da082000"
      },
      "outputs": [],
      "source": [
        "LOADING = False\n",
        "TRAINING = True\n",
        "MODULATE = False\n",
        "\n",
        "start = 30\n",
        "epochs = 100\n",
        "batch_size = 8\n",
        "lr = 1e-4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Channels ===\n",
        "OUT_CHANNELS = 5\n",
        "IN_CHANNELS = 5\n",
        "if MODULATE:\n",
        "    CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wE1yFewM24G7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "wE1yFewM24G7",
        "outputId": "7911fd40-95bb-4c34-fb61-6025ffb1bdf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVUSA_subset/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0036703_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0036703_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVUSA_subset/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0029179_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0029179_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CVUSA_subset/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0042629_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0042629_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CVUSA_subset/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0008799_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0008799_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CVUSA_subset/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0007279_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0007279_mask...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       0                                    1  \\\n",
              "0  CVUSA_subset/bingmap/input0036703.png  CVUSA_subset/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/bingmap/input0029179.png  CVUSA_subset/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/bingmap/input0042629.png  CVUSA_subset/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/bingmap/input0008799.png  CVUSA_subset/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/bingmap/input0007279.png  CVUSA_subset/streetview/0007279.jpg   \n",
              "\n",
              "                                                   2  \\\n",
              "0  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "1  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "2  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "3  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "4  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "\n",
              "                                                   3  \\\n",
              "0  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "1  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "2  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "3  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "4  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "\n",
              "                                             4  \\\n",
              "0  CVUSA_subset/depth/bingmap/input0036703.png   \n",
              "1  CVUSA_subset/depth/bingmap/input0029179.png   \n",
              "2  CVUSA_subset/depth/bingmap/input0042629.png   \n",
              "3  CVUSA_subset/depth/bingmap/input0008799.png   \n",
              "4  CVUSA_subset/depth/bingmap/input0007279.png   \n",
              "\n",
              "                                           5  \\\n",
              "0  CVUSA_subset/depth/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/depth/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/depth/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/depth/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/depth/streetview/0007279.jpg   \n",
              "\n",
              "                                                  6  \\\n",
              "0  CVUSA_subset/segmap_new/bingmap/input0036703.png   \n",
              "1  CVUSA_subset/segmap_new/bingmap/input0029179.png   \n",
              "2  CVUSA_subset/segmap_new/bingmap/input0042629.png   \n",
              "3  CVUSA_subset/segmap_new/bingmap/input0008799.png   \n",
              "4  CVUSA_subset/segmap_new/bingmap/input0007279.png   \n",
              "\n",
              "                                                7  \\\n",
              "0  CVUSA_subset/segmap_new/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/segmap_new/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/segmap_new/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/segmap_new/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/segmap_new/streetview/0007279.jpg   \n",
              "\n",
              "                                                   8  \\\n",
              "0  CVUSA_subset/segformer/satellite/input0036703_...   \n",
              "1  CVUSA_subset/segformer/satellite/input0029179_...   \n",
              "2  CVUSA_subset/segformer/satellite/input0042629_...   \n",
              "3  CVUSA_subset/segformer/satellite/input0008799_...   \n",
              "4  CVUSA_subset/segformer/satellite/input0007279_...   \n",
              "\n",
              "                                                   9  \n",
              "0  CVUSA_subset/segformer/streetview/0036703_mask...  \n",
              "1  CVUSA_subset/segformer/streetview/0029179_mask...  \n",
              "2  CVUSA_subset/segformer/streetview/0042629_mask...  \n",
              "3  CVUSA_subset/segformer/streetview/0008799_mask...  \n",
              "4  CVUSA_subset/segformer/streetview/0007279_mask...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_path = r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\CVUSA_subset\\file_paths_seg.csv\"\n",
        "df_t = pd.read_csv(csv_path, sep=\",\", header=None)\n",
        "df = df_t.copy()\n",
        "\n",
        "base_folder = r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\"\n",
        "\n",
        "def make_correct_path(rel_path):\n",
        "    filename = os.path.basename(rel_path).split('.')[0]\n",
        "\n",
        "    new_filename = f\"{filename}_mask.png\"\n",
        "\n",
        "    correct_rel_path = os.path.join(\"CVUSA_subset\", \"segformer\", \"streetview\", new_filename)\n",
        "    return correct_rel_path.replace(\"\\\\\", \"/\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QqM0IMjG3_yi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqM0IMjG3_yi",
        "outputId": "e228144b-39e7-4e2e-a198-72c1325da317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\CVUSA_subset\\segmap_new\\streetview\\0036703.jpg\n"
          ]
        }
      ],
      "source": [
        "path = os.path.join(base_folder, df[7][0])\n",
        "normalized_path = os.path.normpath(path)\n",
        "\n",
        "print(normalized_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbdLZoAC3ssg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbdLZoAC3ssg",
        "outputId": "d2920330-7f88-4e5e-9e23-ed875cc6b5ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndf['segformer_exists'] = df[7].apply(lambda rel_path: os.path.exists(os.path.join(base_folder, rel_path)))\\nprint(df[['segformer_exists']].head())  # Just first few rows'\\n\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "df['segformer_exists'] = df[7].apply(lambda rel_path: os.path.exists(os.path.join(base_folder, rel_path)))\n",
        "print(df[['segformer_exists']].head())  # Just first few rows'\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IsklijQ8ulZq",
      "metadata": {
        "id": "IsklijQ8ulZq"
      },
      "outputs": [],
      "source": [
        "class RGBD_Image():\n",
        "    def __init__(self, rgb_src, depth_src, max_depth=1.0, modulation=False):\n",
        "        super(RGBD_Image, self).__init__()\n",
        "        self.rgb = rgb_src\n",
        "        self.depth = depth_src\n",
        "        self.max_depth = max_depth\n",
        "        self.modulation = modulation\n",
        "\n",
        "    def transform(self):\n",
        "        x, y = self.rgb, self.depth\n",
        "        y = y.astype(np.float32) / 255.0 * self.max_depth\n",
        "        rgb_norm = x.astype(np.float32) / 255.0\n",
        "        depth_norm = np.expand_dims(y / np.max(y + 1e-8), axis=2)\n",
        "        if self.modulation:\n",
        "            return rgb_norm * depth_norm\n",
        "        else:\n",
        "            return np.concatenate((rgb_norm, depth_norm), axis=2)\n",
        "        \n",
        "class CVUSA_Dataset(Dataset):\n",
        "    def __init__(self, df, path, size=256, transform=True, modulation=False, is_test=False, augmentation=False):\n",
        "        super(CVUSA_Dataset, self).__init__()\n",
        "        self.size = size\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.modulation = modulation\n",
        "        self.is_test = is_test\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "        self.Ttor = T.Compose([T.ToTensor(), T.Resize((self.size, self.size))])\n",
        "\n",
        "        seg_col = 'seg_sat'\n",
        "        seg_col_out = 'seg_street'\n",
        "        self.train_df, self.test_df = self._splitter(df)\n",
        "\n",
        "        if augmentation:\n",
        "            self.Ator = T.Compose([T.RandomHorizontalFlip(0.3)])\n",
        "\n",
        "        if self.is_test:\n",
        "            self.sv_images = [os.path.join(path, x) for x in self.test_df['streetview']]\n",
        "            self.sat_images = [os.path.join(path, x) for x in self.test_df['bingmap']]\n",
        "            self.depth_svs = [os.path.join(path, x) for x in self.test_df['depth_sv']]\n",
        "            self.depth_bms = [os.path.join(path, x) for x in self.test_df['depth_bm']]\n",
        "            self.segmented_bms = [os.path.join(path, x) for x in self.test_df[seg_col]]\n",
        "            self.segmented_bms_out = [os.path.join(path, x) for x in self.test_df[seg_col_out]]\n",
        "\n",
        "            train_sv = [os.path.join(path, x) for x in self.train_df['streetview']]\n",
        "            train_dp = [os.path.join(path, x) for x in self.train_df['depth_sv']]\n",
        "\n",
        "            self.mean, self.std = self._compute_mean_std(sv_images=train_sv, depth_svs=train_dp)\n",
        "        else:\n",
        "            self.sv_images = [os.path.join(path, x) for x in self.train_df['streetview']]\n",
        "            self.sat_images = [os.path.join(path, x) for x in self.train_df['bingmap']]\n",
        "            self.depth_svs = [os.path.join(path, x) for x in self.train_df['depth_sv']]\n",
        "            self.depth_bms = [os.path.join(path, x) for x in self.train_df['depth_bm']]\n",
        "            self.segmented_bms = [os.path.join(path, x) for x in self.train_df[seg_col]]\n",
        "            self.segmented_bms_out = [os.path.join(path, x) for x in self.train_df[seg_col_out]]\n",
        "\n",
        "            self.mean, self.std = self._compute_mean_std(sv_images=self.sv_images, depth_svs=self.depth_svs)\n",
        "\n",
        "        self.Ntor = T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=self.mean, std=self.std),\n",
        "            T.Resize((self.size, self.size))\n",
        "        ])\n",
        "\n",
        "    def _splitter(self, df):\n",
        "        dim = int(0.7 * len(df))\n",
        "        return df[:dim], df[dim:]\n",
        "\n",
        "    def _compute_mean_std(self, sv_images, depth_svs):\n",
        "        stats_dir = os.path.join(self.path, \"stats\")\n",
        "        os.makedirs(stats_dir, exist_ok=True)\n",
        "        json_path = os.path.join(stats_dir, 'modulated_stats.json' if self.modulation else 'stats.json')\n",
        "\n",
        "        if os.path.exists(json_path) and os.path.getsize(json_path) > 0:\n",
        "            with open(json_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                return np.array(data['mean']), np.array(data['std'])\n",
        "\n",
        "        means = np.zeros(4 if not self.modulation else 3)\n",
        "        sq_means = np.zeros_like(means)\n",
        "        count = 0\n",
        "\n",
        "        for idx in tqdm(range(len(sv_images)), desc=\"Computing mean/std\"):\n",
        "            sv_img = cv2.cvtColor(cv2.imread(sv_images[idx]), cv2.COLOR_BGR2RGB)\n",
        "            depth = cv2.imread(depth_svs[idx], cv2.IMREAD_GRAYSCALE)\n",
        "            rgbd = RGBD_Image(sv_img, depth, max_depth=100.0, modulation=self.modulation).transform()\n",
        "            means += np.mean(rgbd, axis=(0, 1))\n",
        "            sq_means += np.mean(rgbd**2, axis=(0, 1))\n",
        "            count += 1\n",
        "\n",
        "        mean = means / count\n",
        "        std = np.sqrt(sq_means / count - mean**2)\n",
        "\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump({'mean': mean.tolist(), 'std': std.tolist()}, f)\n",
        "\n",
        "        return mean, std\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sv_img = cv2.cvtColor(cv2.imread(self.sv_images[index]), cv2.COLOR_BGR2RGB)\n",
        "        sat_img = cv2.cvtColor(cv2.imread(self.sat_images[index]), cv2.COLOR_BGR2RGB)\n",
        "        depth_sv = cv2.imread(self.depth_svs[index], cv2.IMREAD_GRAYSCALE)\n",
        "        depth_bm = cv2.imread(self.depth_bms[index], cv2.IMREAD_GRAYSCALE)\n",
        "        filename = basename(self.sv_images[index])\n",
        "\n",
        "\n",
        "        seg_in = cv2.imread(self.segmented_bms[index], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        seg_out = cv2.imread(self.segmented_bms_out[index], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        sv_img = cv2.resize(sv_img, (self.size, self.size), interpolation=cv2.INTER_AREA)\n",
        "        depth_sv = cv2.resize(depth_sv, (self.size, self.size), interpolation=cv2.INTER_AREA)\n",
        "        seg_in = cv2.resize(seg_in, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
        "        seg_out = cv2.resize(seg_out, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        rgbd = RGBD_Image(sv_img, depth_sv, max_depth=100.0, modulation=self.modulation).transform().astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            rgbd = self.Ntor(rgbd)\n",
        "\n",
        "        if self.augmentation:\n",
        "            rgbd = self.Ator(rgbd)\n",
        "\n",
        "        sat_img = cv2.resize(sat_img, (self.size, self.size), interpolation=cv2.INTER_AREA)\n",
        "        depth_bm = cv2.resize(depth_bm, (self.size, self.size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        sat_rgbd = RGBD_Image(sat_img, depth_bm, max_depth=100000.0, modulation=self.modulation).transform().astype(np.float32)\n",
        "\n",
        "        sat_rgbd = self.Ttor(sat_rgbd)\n",
        "\n",
        "        seg_in_float = torch.tensor(seg_in / 255., dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        rgbd = torch.cat([rgbd, seg_in_float], dim=0)\n",
        "        sat_rgbd = torch.cat([sat_rgbd, seg_in_float], dim=0)\n",
        "\n",
        "        seg_out_tensor = torch.tensor(seg_out, dtype=torch.long)\n",
        "\n",
        "        return rgbd, sat_rgbd, seg_out_tensor, filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sv_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899455bf",
      "metadata": {
        "id": "899455bf"
      },
      "source": [
        "#### Loss & optimizer initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761453b8",
      "metadata": {
        "id": "761453b8"
      },
      "outputs": [],
      "source": [
        "# === Loss ===\n",
        "segmentation_loss = nn.CrossEntropyLoss()\n",
        "adversarial_loss = nn.BCELoss()\n",
        "pixelwise_loss = nn.L1Loss()\n",
        "\n",
        "# === Optimizers ===\n",
        "optimizer_G = optim.Adam(list(generator.encoder.parameters()) + list(generator.decoder.parameters()), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, mode='min', factor=0.7, patience=3, min_lr=1e-5)\n",
        "optimizer_D = optim.Adam(discriminator.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rf_GSD2GGqOI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rf_GSD2GGqOI",
        "outputId": "6c953c5a-e9c4-4d7e-f67f-bba14015e69e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nprint(df[\\'streetview\\'].apply(type).value_counts())\\nprint(df[\\'streetview\\'][df[\\'streetview\\'].apply(lambda x: not isinstance(x, str))])\\n#print(pd.read_csv(csv_path, sep=\"\\t\", header=None).head())\\n#print(pd.read_csv(csv_path, sep=\",\", header=None).head())\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "print(df['streetview'].apply(type).value_counts())\n",
        "print(df['streetview'][df['streetview'].apply(lambda x: not isinstance(x, str))])\n",
        "#print(pd.read_csv(csv_path, sep=\"\\t\", header=None).head())\n",
        "#print(pd.read_csv(csv_path, sep=\",\", header=None).head())\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f7cc97",
      "metadata": {},
      "source": [
        "## UTILS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7852115b",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_save_path = r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\seg_in_out\"\n",
        "\n",
        "def save_samples(loops=1, epoch=0):\n",
        "    image_counter = 1\n",
        "    max_images = loops * batch_size\n",
        "\n",
        "    for rgbde_batch, sat_batch, seg_map in valid_loader:\n",
        "        if image_counter > max_images:\n",
        "            break\n",
        "\n",
        "        rgbde_batch = rgbde_batch.to(device)\n",
        "        gen_images = generator(rgbde_batch).detach().cpu()\n",
        "        rgbde_batch = rgbde_batch.cpu()\n",
        "\n",
        "        mean = torch.tensor(data_set.mean[:3])\n",
        "        std = torch.tensor(data_set.std[:3])\n",
        "\n",
        "        limit = min(batch_size, rgbde_batch.size(0))\n",
        "        for i in range(limit):\n",
        "            if image_counter > max_images:\n",
        "                break\n",
        "\n",
        "            rgb = rgbde_batch[i][:3] * std[:, None, None] + mean[:, None, None]\n",
        "            rgb = torch.clamp(rgb, 0, 1).permute(1, 2, 0).numpy()\n",
        "\n",
        "            sat_real = torch.clamp(sat_batch[i][:3], 0, 1).permute(1, 2, 0).numpy()\n",
        "            sat_fake = torch.clamp(gen_images[i][:3], 0, 1).permute(1, 2, 0).numpy()\n",
        "\n",
        "            fig, axs = plt.subplots(1, 5, figsize=(12, 4))\n",
        "            axs[0].imshow(rgb); axs[0].set_title(\"Input RGB\"); axs[0].axis(\"off\")\n",
        "            axs[1].imshow(sat_fake); axs[1].set_title(\"Generated Satellite\"); axs[1].axis(\"off\")\n",
        "            axs[2].imshow(sat_real); axs[2].set_title(\"Real Satellite\"); axs[2].axis(\"off\")\n",
        "            # axs[3]... etc.\n",
        "\n",
        "            plt.tight_layout()\n",
        "            save_path = os.path.join(base_save_path, f\"epoch_{epoch:03}_fig_{image_counter}.png\")\n",
        "            #print(f\"Saving figure to: {save_path}\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "\n",
        "            image_counter += 1\n",
        "    print(f\"Saved images\")\n",
        "    \n",
        "\n",
        "def compute_lambda(epoch, warmup_epochs=5, lambda_start=100.0, decay_rate=0.95):\n",
        "    if epoch < warmup_epochs:\n",
        "        return lambda_start\n",
        "    else:\n",
        "        return lambda_start * (decay_rate ** (epoch - warmup_epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b754f76",
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "def compute_psnr_torch(output, target):\n",
        "    output_np = output[:3].detach().cpu().numpy()\n",
        "    target_np = target[:3].detach().cpu().numpy()\n",
        "    return psnr(target_np, output_np, data_range=target_np.max() - target_np.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "366c8686",
      "metadata": {
        "id": "366c8686"
      },
      "source": [
        "## DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d63c082",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d63c082",
        "outputId": "9a1a1fed-fffb-4cec-9310-fa3af0679c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\CVUSA_subset\\file_paths_seg.csv\n"
          ]
        }
      ],
      "source": [
        "path = r\"C:\\Users\\fede6\\Desktop\\AI_R\\DatasetCV\" # r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\"\n",
        "csv_path = r\"C:\\Users\\fede6\\Desktop\\AI_R\\DatasetCV\\CVUSA_subset\\file_paths_new.csv\"  # os.path.join(path, \"CVUSA_subset\", \"file_paths_seg.csv\")\n",
        "\n",
        "print(csv_path)\n",
        "df = pd.read_csv(\n",
        "    csv_path,\n",
        "    sep=\",\",\n",
        "    names=['bingmap', 'streetview', 'sift_bm', 'sift_sv', 'depth_bm', 'depth_sv', 'segmap_bm', 'segmap_sv', 'seg_sat', 'seg_street', ],\n",
        "    encoding='utf-8',\n",
        "    header=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FmYt3RA92-vL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "FmYt3RA92-vL",
        "outputId": "d2464fc9-23d9-4cf5-ef63-8cf260e9c9db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bingmap</th>\n",
              "      <th>streetview</th>\n",
              "      <th>sift_bm</th>\n",
              "      <th>sift_sv</th>\n",
              "      <th>depth_bm</th>\n",
              "      <th>depth_sv</th>\n",
              "      <th>segmap_bm</th>\n",
              "      <th>segmap_sv</th>\n",
              "      <th>seg_sat</th>\n",
              "      <th>seg_street</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVUSA_subset/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0036703.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0036703.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0036703_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0036703_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVUSA_subset/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0029179.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0029179.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0029179_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0029179_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CVUSA_subset/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0042629.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0042629.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0042629_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0042629_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CVUSA_subset/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0008799.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0008799.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0008799_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0008799_mask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CVUSA_subset/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/sift/bingmap/sift_visualized_inpu...</td>\n",
              "      <td>CVUSA_subset/sift/streetview/sift_visualized_0...</td>\n",
              "      <td>CVUSA_subset/depth/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/depth/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/segmap_new/bingmap/input0007279.png</td>\n",
              "      <td>CVUSA_subset/segmap_new/streetview/0007279.jpg</td>\n",
              "      <td>CVUSA_subset/segformer/satellite/input0007279_...</td>\n",
              "      <td>CVUSA_subset/segformer/streetview/0007279_mask...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 bingmap                           streetview  \\\n",
              "0  CVUSA_subset/bingmap/input0036703.png  CVUSA_subset/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/bingmap/input0029179.png  CVUSA_subset/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/bingmap/input0042629.png  CVUSA_subset/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/bingmap/input0008799.png  CVUSA_subset/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/bingmap/input0007279.png  CVUSA_subset/streetview/0007279.jpg   \n",
              "\n",
              "                                             sift_bm  \\\n",
              "0  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "1  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "2  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "3  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "4  CVUSA_subset/sift/bingmap/sift_visualized_inpu...   \n",
              "\n",
              "                                             sift_sv  \\\n",
              "0  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "1  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "2  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "3  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "4  CVUSA_subset/sift/streetview/sift_visualized_0...   \n",
              "\n",
              "                                      depth_bm  \\\n",
              "0  CVUSA_subset/depth/bingmap/input0036703.png   \n",
              "1  CVUSA_subset/depth/bingmap/input0029179.png   \n",
              "2  CVUSA_subset/depth/bingmap/input0042629.png   \n",
              "3  CVUSA_subset/depth/bingmap/input0008799.png   \n",
              "4  CVUSA_subset/depth/bingmap/input0007279.png   \n",
              "\n",
              "                                    depth_sv  \\\n",
              "0  CVUSA_subset/depth/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/depth/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/depth/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/depth/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/depth/streetview/0007279.jpg   \n",
              "\n",
              "                                          segmap_bm  \\\n",
              "0  CVUSA_subset/segmap_new/bingmap/input0036703.png   \n",
              "1  CVUSA_subset/segmap_new/bingmap/input0029179.png   \n",
              "2  CVUSA_subset/segmap_new/bingmap/input0042629.png   \n",
              "3  CVUSA_subset/segmap_new/bingmap/input0008799.png   \n",
              "4  CVUSA_subset/segmap_new/bingmap/input0007279.png   \n",
              "\n",
              "                                        segmap_sv  \\\n",
              "0  CVUSA_subset/segmap_new/streetview/0036703.jpg   \n",
              "1  CVUSA_subset/segmap_new/streetview/0029179.jpg   \n",
              "2  CVUSA_subset/segmap_new/streetview/0042629.jpg   \n",
              "3  CVUSA_subset/segmap_new/streetview/0008799.jpg   \n",
              "4  CVUSA_subset/segmap_new/streetview/0007279.jpg   \n",
              "\n",
              "                                             seg_sat  \\\n",
              "0  CVUSA_subset/segformer/satellite/input0036703_...   \n",
              "1  CVUSA_subset/segformer/satellite/input0029179_...   \n",
              "2  CVUSA_subset/segformer/satellite/input0042629_...   \n",
              "3  CVUSA_subset/segformer/satellite/input0008799_...   \n",
              "4  CVUSA_subset/segformer/satellite/input0007279_...   \n",
              "\n",
              "                                          seg_street  \n",
              "0  CVUSA_subset/segformer/streetview/0036703_mask...  \n",
              "1  CVUSA_subset/segformer/streetview/0029179_mask...  \n",
              "2  CVUSA_subset/segformer/streetview/0042629_mask...  \n",
              "3  CVUSA_subset/segformer/streetview/0008799_mask...  \n",
              "4  CVUSA_subset/segformer/streetview/0007279_mask...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IomPaZmn2940",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IomPaZmn2940",
        "outputId": "f499202b-f7dd-4d48-fd62-b6f9c97cae94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero di campioni in data: 6203\n",
            "Numero di campioni in test: 2659\n",
            "Numero items totale: 8862\n"
          ]
        }
      ],
      "source": [
        "data_set = CVUSA_Dataset(df, path, transform=True, size=256, modulation=MODULATE, is_test=False)\n",
        "print(f\"Numero di campioni in data: {len(data_set)}\")\n",
        "\n",
        "test_set = CVUSA_Dataset(df, path, transform=True, size=256, modulation=MODULATE, is_test=True)\n",
        "print(f\"Numero di campioni in test: {len(test_set)}\")\n",
        "\n",
        "gen = torch.Generator().manual_seed(42)\n",
        "valid_set, test_set = torch.utils.data.random_split(test_set, [0.5, 0.5], generator=gen)\n",
        "train_loader = DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Numero items totale: {len(test_set) + len(data_set) +len(valid_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GLZmy5IYJTN6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLZmy5IYJTN6",
        "outputId": "47285ac9-ac63-4702-d769-e0cdfca176f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero di campioni in data: 6203\n",
            "Numero di campioni in train_set: 6203\n",
            "Numero di campioni in valid_set: 1330\n",
            "Numero di campioni in test_set: 1329\n"
          ]
        }
      ],
      "source": [
        "print(f\"Numero di campioni in data: {len(data_set)}\")\n",
        "print(f\"Numero di campioni in train_set: {len(train_loader.dataset)}\")\n",
        "print(f\"Numero di campioni in valid_set: {len(valid_set)}\")\n",
        "print(f\"Numero di campioni in test_set: {len(test_set)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcdccf9",
      "metadata": {},
      "source": [
        "## NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8deaae",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=8, ndf=64):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ndf, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1),   \n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=1, padding=1),   \n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 8, 1, 4, stride=1, padding=1),         \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input_cat = torch.cat([x, y], dim=1)\n",
        "        return self.model(input_cat)\n",
        "\n",
        "class SwinEncoder(nn.Module):\n",
        "    def __init__(self, num_channels=5):\n",
        "        super(SwinEncoder, self).__init__()\n",
        "        if num_channels == 3:\n",
        "            weights = Swin_T_Weights.IMAGENET1K_V1\n",
        "            self.model = swin_t(weights=weights)\n",
        "            self.features = nn.Sequential(\n",
        "                self.model.features\n",
        "            )\n",
        "        elif num_channels == 4:\n",
        "            weights = Swin_T_Weights.IMAGENET1K_V1\n",
        "            self.model = swin_t(weights=weights)\n",
        "            features = list(self.model.features)\n",
        "\n",
        "            first_conv = nn.Conv2d(num_channels, features[0][0].out_channels, kernel_size=features[0][0].kernel_size,\n",
        "                                stride=features[0][0].stride, padding=features[0][0].padding)\n",
        "\n",
        "            if num_channels == 4 and features[0][0].in_channels == 3:\n",
        "                with torch.no_grad():\n",
        "                    weight = features[0][0].weight.data\n",
        "                    first_conv.weight.data[:, :3, :, :] = weight\n",
        "                    first_conv.weight.data[:, 3, :, :] = weight.mean(dim=1)\n",
        "                if features[0][0].bias is not None:\n",
        "                    first_conv.bias.data = features[0][0].bias.data\n",
        "\n",
        "            features[0][0] = first_conv\n",
        "\n",
        "            self.features = nn.Sequential(*features)\n",
        "        elif num_channels == 5:\n",
        "            weights = Swin_T_Weights.IMAGENET1K_V1\n",
        "            self.model = swin_t(weights=weights)\n",
        "            features = list(self.model.features)\n",
        "\n",
        "            first_conv = nn.Conv2d(num_channels, features[0][0].out_channels, kernel_size=features[0][0].kernel_size,\n",
        "                                stride=features[0][0].stride, padding=features[0][0].padding)\n",
        "\n",
        "            if num_channels == 5 and features[0][0].in_channels == 3:\n",
        "                with torch.no_grad():\n",
        "                    weight = features[0][0].weight.data\n",
        "                    first_conv.weight.data[:, :3, :, :] = weight\n",
        "                    first_conv.weight.data[:, 3, :, :] = weight.mean(dim=1)\n",
        "                    first_conv.weight.data[:, 4, :, :] = weight.mean(dim=1)\n",
        "                if features[0][0].bias is not None:\n",
        "                    first_conv.bias.data = features[0][0].bias.data\n",
        "\n",
        "            features[0][0] = first_conv\n",
        "\n",
        "            self.features = nn.Sequential(*features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "class SwinDecoder(nn.Module):\n",
        "    def __init__(self, in_channels=768, out_channels=3):\n",
        "        super(SwinDecoder, self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, 384, 4, 2, 1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(384, 192, 4, 2, 1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(192, 96, 4, 2, 1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(96, 48, 4, 2, 1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(48, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "class SwinGenerator(nn.Module):\n",
        "    def __init__(self, in_channels=5, out_channels=3):\n",
        "        super(SwinGenerator, self).__init__()\n",
        "        self.encoder = SwinEncoder(num_channels=in_channels)\n",
        "        self.decoder = SwinDecoder(out_channels=out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x).permute(0, 3, 1, 2)\n",
        "        reconstruction = self.decoder(feats)\n",
        "        return reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f625ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "gen = SwinGenerator(in_channels=5, out_channels=5)\n",
        "x = torch.randn(1, 5, 224, 224)\n",
        "out = gen(x)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8858548d",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LOADING:\n",
        "    print(\"Loading previous states...\", end=\" \")\n",
        "    checkpoint = torch.load(f\"/content/gdrive/VISION_PROJECT/models/GAN_{start}.pt\")\n",
        "    generator = SwinGenerator(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS).to(device)\n",
        "    discriminator = PatchDiscriminator(in_channels=IN_CHANNELS + OUT_CHANNELS, ndf=4).to(device)\n",
        "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    print(\"Done.\")\n",
        "else:\n",
        "    start = 0\n",
        "    generator = SwinGenerator(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS).to(device)\n",
        "    discriminator = PatchDiscriminator(in_channels=IN_CHANNELS + OUT_CHANNELS, ndf=16).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be64aa08",
      "metadata": {
        "id": "be64aa08"
      },
      "source": [
        "## TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911c339d",
      "metadata": {
        "id": "911c339d"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5ea49e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5ea49e",
        "outputId": "3d6b6b51-8572-4915-bdea-1d95fa43e67a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                                       \n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if TRAINING:\n",
        "    for epoch in range(start, epochs):\n",
        "        #generator.train()\n",
        "        #discriminator.train()\n",
        "        #g_loss_total = 0.0\n",
        "        #d_loss_total = 0.0\n",
        "        #seg_loss_total = 0.0\n",
        "        #\n",
        "        lambda_rec = compute_lambda(epoch)\n",
        "        #\n",
        "        #loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
        "        #d_real_scores = []\n",
        "        #d_fake_scores = []\n",
        "        #\n",
        "        #\n",
        "        #for rgbd, sat, segment, filename in loop:\n",
        "        #    rgbd, sat = rgbd.to(device), sat.to(device)\n",
        "        #\n",
        "        #    optimizer_D.zero_grad()\n",
        "        #    real_validity = discriminator(rgbd, sat)\n",
        "        #    real_labels = torch.empty_like(real_validity).uniform_(0.90, 1.0).to(device)\n",
        "        #    d_real_loss = adversarial_loss(real_validity, real_labels)\n",
        "        #\n",
        "        #    fake_sat = generator(rgbd).detach()\n",
        "        #    fake_validity = discriminator(rgbd, fake_sat)\n",
        "        #    fake_labels = torch.empty_like(fake_validity).uniform_(0.0, 0.1).to(device)\n",
        "        #    d_fake_loss = adversarial_loss(fake_validity, fake_labels)\n",
        "        #   \n",
        "        #    d_loss = (d_real_loss + d_fake_loss) * 0.5\n",
        "        #    d_loss.backward()\n",
        "        #    optimizer_D.step()\n",
        "        #\n",
        "        #    optimizer_G.zero_grad()\n",
        "        #    gen_output = generator(rgbd)\n",
        "        #    pred_validity = discriminator(rgbd, gen_output)\n",
        "        #    g_adv_loss = adversarial_loss(pred_validity, real_labels)\n",
        "        #    g_recon_loss = pixelwise_loss(gen_output, sat)\n",
        "        #    g_loss = 0.01 * g_adv_loss + lambda_rec * g_recon_loss\n",
        "        #       \n",
        "        #    g_loss.backward()\n",
        "        #    optimizer_G.step()\n",
        "        #\n",
        "        #    g_loss_total += g_loss.item()\n",
        "        #    d_loss_total += d_loss.item()\n",
        "        #\n",
        "        #    loop.set_postfix(G_Loss=g_loss_total, D_Loss=d_loss_total)\n",
        "        #\n",
        "        #    d_real_scores.append(real_validity.mean().item())\n",
        "        #    d_fake_scores.append(fake_validity.mean().item())\n",
        "\n",
        "        # === Validation ===\n",
        "        generator.eval()\n",
        "        val_g_loss = 0.0\n",
        "        val_seg_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for rgbd_val, sat_val, seg_val in tqdm(valid_loader):\n",
        "                rgbd_val, sat_val = rgbd_val.to(device), sat_val.to(device)\n",
        "                gen_val = generator(rgbd_val)\n",
        "                pred_val = discriminator(rgbd_val, gen_val)\n",
        "                g_adv_val = adversarial_loss(pred_val, torch.ones_like(pred_val).to(device))\n",
        "                g_recon_val = pixelwise_loss(gen_val, sat_val)\n",
        "                val_g_loss += (g_adv_val + lambda_rec * g_recon_val).item()\n",
        "                \n",
        "                for i in range(gen_val.size(0)):\n",
        "                    psnr_val = compute_psnr_torch(gen_val[i], sat_val[i])\n",
        "                    psnr_total += psnr_val\n",
        "\n",
        "            avg_psnr = psnr_total / len(valid_loader.dataset)\n",
        "            print(f\"Average PSNR on validation: {avg_psnr:.2f} dB\")\n",
        "        #avg_train_g_loss = g_loss_total / len(train_loader)\n",
        "        #avg_train_seg_loss = seg_loss_total / len(train_loader)\n",
        "        #avg_val_g_loss = val_g_loss / len(valid_loader)\n",
        "        #scheduler.step(avg_val_g_loss)\n",
        "        #avg_d_loss = d_loss_total / len(train_loader)\n",
        "\n",
        "        # print(f\"[Epoch {epoch+1}/{epochs}] Train G Loss: {avg_train_g_loss:.4f} | Val G Loss: {avg_val_g_loss:.4f} | D Loss: {avg_d_loss:.4f}\")\n",
        "\n",
        "        #avg_d_real_score = sum(d_real_scores) / len(d_real_scores)\n",
        "        #avg_d_fake_score = sum(d_fake_scores) / len(d_fake_scores)\n",
        "\n",
        "        #print(f\"D(real): {avg_d_real_score:.4f} | D(fake): {avg_d_fake_score:.4f}\")\n",
        "\n",
        "        #current_lr = optimizer_G.param_groups[0]['lr']\n",
        "        #print(f\"Current learning rate: {current_lr}\")\n",
        "\n",
        "        #checkpoint = {\n",
        "        #    'epoch': epoch + 1,\n",
        "        #    'generator_state_dict': generator.state_dict(),\n",
        "        #    'discriminator_state_dict': discriminator.state_dict(),\n",
        "        #    'G_rec_loss': avg_train_g_loss,\n",
        "        #    'G_rec_val_loss': avg_val_g_loss,\n",
        "        #    'discriminator_loss': avg_d_loss\n",
        "        #}\n",
        "\n",
        "        #torch.save(checkpoint, fr\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\seg_in_out_check\\GAN_{epoch + 1}.pt\")\n",
        "        #save_samples(epoch=epoch + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963f66b2",
      "metadata": {
        "id": "963f66b2"
      },
      "source": [
        "## GENERATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553b34d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "553b34d3",
        "outputId": "2556e16c-b413-4875-ef3e-46197d804689"
      },
      "outputs": [],
      "source": [
        "save_samples(loops=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0QOrmgU4A02n",
      "metadata": {
        "id": "0QOrmgU4A02n"
      },
      "outputs": [],
      "source": [
        "def write_samples(generator, loader, path, dir_name=\"val_set\"):\n",
        "    generator.eval()\n",
        "    save_dir = os.path.join(path, dir_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, (rgbd_batch, _, _, filenames) in enumerate(tqdm(loader)):\n",
        "            rgbd_batch = rgbd_batch.to(device)\n",
        "            gen_images = generator(rgbd_batch).cpu()\n",
        "\n",
        "            for j in range(len(gen_images)):\n",
        "                image = torch.clamp(gen_images[j][:3], 0, 1).permute(1, 2, 0).numpy()\n",
        "                image_uint8 = (image * 255).astype(np.uint8)\n",
        "                image_bgr = cv2.cvtColor(image_uint8, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                base_name = os.path.splitext(filenames[j])[0] + \"_generated.png\"\n",
        "                save_path = os.path.join(save_dir, base_name)\n",
        "                cv2.imwrite(save_path, image_bgr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aKa0V0ayC4Aj",
      "metadata": {
        "id": "aKa0V0ayC4Aj"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\seg_in_out_check\\half_smoothing\\GAN_55.pt\"\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "generator.eval()\n",
        "\n",
        "if not sys.warnoptions:\n",
        "  warnings.simplefilter(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cnzZ_IpFCBj2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzZ_IpFCBj2",
        "outputId": "af5ba0d2-2a81-4b50-eaa4-7cbe230c5de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 776/776 [03:06<00:00,  4.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "write_samples(\n",
        "    generator=generator,\n",
        "    loader=train_loader,\n",
        "    path=r\"C:\\Users\\Alessia\\Downloads\\VISION_PROJECT\\seg_in_out\",\n",
        "    dir_name=\"generated\"\n",
        ")\n",
        "print(len(valid_loader)*8)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
